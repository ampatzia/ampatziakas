load("C:/Users/Kostas/Desktop/Antonis - PHQ RF models/grid_search_res.Rda")
load("C:/Users/Kostas/Desktop/Antonis - PHQ RF models/imputed_period_ready.Rda")
#library(rpart)
library(caret)
#library(rpart.plot)
library(CORElearn)
#library(MASS)
#library(mlbench)
#library(alr3)
library(dplyr)
library(purrr)
set.seed(123)
df1<-df_all_plain
df1$PHQb<-cut(df1$PHQsum ,c(0,5,Inf))
levels(df1$PHQb)<-c("None","Depression")
df1<-select(df1,PHQb,Subject,Walk_Speed,Gait,Stand,Hand_Mouth,Tablet,WWU,Speech,S_Speed,S_Arousal,TV)
split_indices<-createDataPartition(df1$PHQb, p = .7, list = FALSE,times = 1)
train_set <- df1[split_indices, ]
test_set <- df1[-split_indices, ]
a<- lapply(res, function(x) predict(x, newdata=test_set, type="class") )
a[[1]]
?predict
a<- lapply(res, function(x)  predict.CoreModel(x, newdata=test_set, type="class") )
a[[1]]
a1<-res[[1]]
a1
predict(a1,newdata=test_set)
test_set
summary(test_set$PHQb)
View(train_set)
predict(a1,newdata=test_set)
a1
predict.CoreModel(a1,newdata=test_set)
a<- lapply(res, function(x)  predict.CoreModel(x, newdata=test_set, type="class") )
bind_rows(a)
aaa<-bind_rows(t(a))
aaa<-bind_cols(t(a))
a[190]
a[10000]
a[1000]
a[1900]
load("C:/Users/Kostas/Desktop/Antonis - PHQ RF models/imputed_period_ready.Rda")
#library(rpart)
library(caret)
#library(rpart.plot)
library(CORElearn)
#library(MASS)
#library(mlbench)
#library(alr3)
library(dplyr)
library(purrr)
set.seed(123)
load("C:/Users/Kostas/Desktop/Antonis - PHQ RF models/imputed_period_ready.Rda")
df1<-df_all_plain
df1$PHQb<-cut(df1$PHQsum ,c(0,5,Inf))
levels(df1$PHQb)<-c("None","Depression")
df1<-select(df1,PHQb,Subject,Walk_Speed,Gait,Stand,Hand_Mouth,Tablet,WWU,Speech,S_Speed,S_Arousal,TV)
split_indices<-createDataPartition(df1$PHQb, p = .7, list = FALSE,times = 1)
train_set <- df1[split_indices, ]
test_set <- df1[-split_indices, ]
#Useless?
#train<-train[complete.cases(train),]
# rownames(train_set)<-c(1:nrow(train))
# rownames(test_set)<-c(1:nrow(test))
grid_search_vars <- list(minNodeWeightRF = seq(1,6,2),
rfNoTrees = seq(10,1000,50),estimators= c( "InfGain",
"MDL", "Gini",  "Accuracy")) %>%  purrr::cross_df()
fit_mod<-function(x,y,z){
fit.rand.forest = CoreModel(PHQb~., data=train_set, model="rf", selectionEstimator=z, minNodeWeightRF=x, rfNoTrees=y)
return(fit.rand.forest)
}
tm<-proc.time()
res<-pmap(list(grid_search_vars$minNodeWeightRF,grid_search_vars$rfNoTrees,grid_search_vars$estimators),fit_mod)
#library(rpart)
library(caret)
#library(rpart.plot)
library(CORElearn)
#library(MASS)
#library(mlbench)
#library(alr3)
library(dplyr)
library(purrr)
set.seed(123)
load("C:/Users/Kostas/Desktop/Antonis - PHQ RF models/imputed_period_ready.Rda")
df1<-df_all_plain
df1$PHQb<-cut(df1$PHQsum ,c(0,5,Inf))
levels(df1$PHQb)<-c("None","Depression")
df1<-select(df1,PHQb,Subject,Walk_Speed,Gait,Stand,Hand_Mouth,Tablet,WWU,Speech,S_Speed,S_Arousal,TV)
split_indices<-createDataPartition(df1$PHQb, p = .7, list = FALSE,times = 1)
train_set <- df1[split_indices, ]
test_set <- df1[-split_indices, ]
#Useless?
#train<-train[complete.cases(train),]
# rownames(train_set)<-c(1:nrow(train))
# rownames(test_set)<-c(1:nrow(test))
grid_search_vars <- list(minNodeWeightRF = seq(1,5,2),
rfNoTrees = seq(10,310,50),estimators= c( "InfGain",
"Gini",  "Accuracy")) %>%  purrr::cross_df()
fit_mod<-function(x,y,z){
fit.rand.forest = CoreModel(PHQb~., data=train_set, model="rf", selectionEstimator=z, minNodeWeightRF=x, rfNoTrees=y)
return(fit.rand.forest)
}
tm<-proc.time()
res<-pmap(list(grid_search_vars$minNodeWeightRF,grid_search_vars$rfNoTrees,grid_search_vars$estimators),fit_mod)
proc.time()-tm
a<- lapply(res, function(x)  predict.CoreModel(x, newdata=test_set, type="class") )
b<-lapply(a, function(x) as.data.frame(t(c(confusionMatrix(x,test_set$PHQb)$overall,
confusionMatrix(x,test_set$PHQb)$byClass))))%>%bind_rows()
df<-bind_cols(grid_search_vars,b)%>% arrange(desc(Accuracy), rfNoTrees, minNodeWeightRF)
df
#library(rpart)
library(caret)
#library(rpart.plot)
library(CORElearn)
#library(MASS)
#library(mlbench)
#library(alr3)
library(dplyr)
library(purrr)
set.seed(123)
load("C:/Users/Kostas/Desktop/Antonis - PHQ RF models/imputed_period_ready.Rda")
df1<-df_all_plain
df1$PHQb<-cut(df1$PHQsum ,c(0,5,Inf))
levels(df1$PHQb)<-c("None","Depression")
df1<-select(df1,PHQb,Walk_Speed,Gait,Stand,Hand_Mouth,Tablet,WWU,Speech,S_Speed,S_Arousal,TV)
split_indices<-createDataPartition(df1$PHQb, p = .7, list = FALSE,times = 1)
train_set <- df1[split_indices, ]
test_set <- df1[-split_indices, ]
#Useless?
#train<-train[complete.cases(train),]
# rownames(train_set)<-c(1:nrow(train))
# rownames(test_set)<-c(1:nrow(test))
grid_search_vars <- list(minNodeWeightRF = seq(1,5,2),
rfNoTrees = seq(10,310,50),estimators= c( "InfGain",
"Gini",  "Accuracy")) %>%  purrr::cross_df()
fit_mod<-function(x,y,z){
fit.rand.forest = CoreModel(PHQb~., data=train_set, model="rf", selectionEstimator=z, minNodeWeightRF=x, rfNoTrees=y)
return(fit.rand.forest)
}
tm<-proc.time()
res<-pmap(list(grid_search_vars$minNodeWeightRF,grid_search_vars$rfNoTrees,grid_search_vars$estimators),fit_mod)
proc.time()-tm
a<- lapply(res, function(x)  predict.CoreModel(x, newdata=test_set, type="class") )
b<-lapply(a, function(x) as.data.frame(t(c(confusionMatrix(x,test_set$PHQb)$overall,
confusionMatrix(x,test_set$PHQb)$byClass))))%>%bind_rows()
df<-bind_cols(grid_search_vars,b)%>% arrange(desc(Accuracy), rfNoTrees, minNodeWeightRF)
df
grid_search_vars <- list(minNodeWeightRF = seq(1,5,1),
rfNoTrees = seq(10,500,50),estimators= c( "InfGain",
"Gini",  "Accuracy")) %>%  purrr::cross_df()
fit_mod<-function(x,y,z){
fit.rand.forest = CoreModel(PHQb~., data=train_set, model="rf", selectionEstimator=z, minNodeWeightRF=x, rfNoTrees=y)
return(fit.rand.forest)
}
tm<-proc.time()
res<-pmap(list(grid_search_vars$minNodeWeightRF,grid_search_vars$rfNoTrees,grid_search_vars$estimators),fit_mod)
proc.time()-tm
a<- lapply(res, function(x)  predict.CoreModel(x, newdata=test_set, type="class") )
b<-lapply(a, function(x) as.data.frame(t(c(confusionMatrix(x,test_set$PHQb)$overall,
confusionMatrix(x,test_set$PHQb)$byClass))))%>%bind_rows()
df<-bind_cols(grid_search_vars,b)%>% arrange(desc(Accuracy), rfNoTrees, minNodeWeightRF)
df
save(df,"2cats_gd.Rda")
setwd("C:/Users/Kostas/Desktop/Antonis - PHQ RF models")
save(df,file="2cats_gd.Rda")
#library(rpart)
library(caret)
#library(rpart.plot)
library(CORElearn)
#library(MASS)
#library(mlbench)
#library(alr3)
library(dplyr)
library(purrr)
set.seed(123)
load("C:/Users/Kostas/Desktop/Antonis - PHQ RF models/imputed_period_ready.Rda")
df1<-df_all_plain
df1$PHQb<-cut(df1$PHQsum ,c(0,5,Inf))
levels(df1$PHQb)<-c("None","Depression")
df1<-select(df1,PHQb,Walk_Speed,Gait,Stand,Hand_Mouth,Tablet,WWU,Speech,S_Speed,S_Arousal,TV)
split_indices<-createDataPartition(df1$PHQb, p = .7, list = FALSE,times = 1)
train_set <- df1[split_indices, ]
test_set <- df1[-split_indices, ]
#Useless?
#train<-train[complete.cases(train),]
# rownames(train_set)<-c(1:nrow(train))
# rownames(test_set)<-c(1:nrow(test))
grid_search_vars <- list(minNodeWeightRF = seq(1,5,1),
rfNoTrees = seq(10,500,50),estimators= c(
"Gini")) %>%  purrr::cross_df()
fit_mod<-function(x,y,z){
fit.rand.forest = CoreModel(PHQb~Walk_Speed+Gait+Stand+Tablet+WWU+Speech+S_Speed+S_Arousal+TV, data=train_set, model="rf", selectionEstimator=z, minNodeWeightRF=x, rfNoTrees=y)
return(fit.rand.forest)
}
tm<-proc.time()
res<-pmap(list(grid_search_vars$minNodeWeightRF,grid_search_vars$rfNoTrees,grid_search_vars$estimators),fit_mod)
proc.time()-tm
a<- lapply(res, function(x)  predict.CoreModel(x, newdata=test_set, type="class") )
b<-lapply(a, function(x) as.data.frame(t(c(confusionMatrix(x,test_set$PHQb)$overall,
confusionMatrix(x,test_set$PHQb)$byClass))))%>%bind_rows()
df<-bind_cols(grid_search_vars,b)%>% arrange(desc(Accuracy), rfNoTrees, minNodeWeightRF)
df
save(df,file="2cats_gd.Rda")
#library(rpart)
library(caret)
#library(rpart.plot)
library(CORElearn)
#library(MASS)
#library(mlbench)
#library(alr3)
library(dplyr)
library(purrr)
set.seed(123)
load("C:/Users/Kostas/Desktop/Antonis - PHQ RF models/imputed_period_ready.Rda")
df1<-df_all_plain
df1$PHQb<-cut(df1$PHQsum ,c(0,4.5,9.5,14.5,Inf))
levels(df1$PHQb)<-c("None","Mild","Moderate","Severe")
df1<-select(df1,PHQb,Walk_Speed,Gait,Stand,Hand_Mouth,Tablet,WWU,Speech,S_Speed,S_Arousal,TV)
split_indices<-createDataPartition(df1$PHQb, p = .7, list = FALSE,times = 1)
train_set <- df1[split_indices, ]
test_set <- df1[-split_indices, ]
#Useless?
#train<-train[complete.cases(train),]
# rownames(train_set)<-c(1:nrow(train))
# rownames(test_set)<-c(1:nrow(test))
grid_search_vars <- list(minNodeWeightRF = seq(1,5,1),
rfNoTrees = seq(10,500,50),estimators= c( "InfGain",
"Gini",  "Accuracy")) %>%  purrr::cross_df()
fit_mod<-function(x,y,z){
fit.rand.forest = CoreModel(PHQb~Walk_Speed+Gait+Stand+Tablet+WWU+Speech+S_Speed+S_Arousal+TV, data=train_set, model="rf", selectionEstimator=z, minNodeWeightRF=x, rfNoTrees=y)
return(fit.rand.forest)
}
tm<-proc.time()
res<-pmap(list(grid_search_vars$minNodeWeightRF,grid_search_vars$rfNoTrees,grid_search_vars$estimators),fit_mod)
proc.time()-tm
a<- lapply(res, function(x)  predict.CoreModel(x, newdata=test_set, type="class") )
b<-lapply(a, function(x) as.data.frame(t(c(confusionMatrix(x,test_set$PHQb)$overall,
confusionMatrix(x,test_set$PHQb)$byClass))))%>%bind_rows()
df<-bind_cols(grid_search_vars,b)%>% arrange(desc(Accuracy), rfNoTrees, minNodeWeightRF)
df
save(df,file="all_cats_gd.Rda")
load("C:/Users/User/Desktop/Antonis - PHQ RF models/delta/period_imp_diff.Rda")
load("C:/Users/Kostas/Desktop/Antonis - PHQ RF models/period_imp_diff.Rda")
#library(rpart)
library(caret)
#library(rpart.plot)
library(CORElearn)
#library(MASS)
#library(mlbench)
#library(alr3)
library(dplyr)
library(purrr)
set.seed(123)
load("C:/Users/Kostas/Desktop/Antonis - PHQ RF models/period_imp_diff.Rda")
df1<-df_delt
df1<-select(df1,health_change,walk_speed,gait,stand,tablet,WWUWorn,speech,speechSpeed,speechArousal,TV)
ss<- createDataPartition(df1$health_change, p = .7,
list = FALSE,
times = 1)
train<-df1[ss,]
test<-df1[-ss,]
#Useless?
#train<-train[complete.cases(train),]
# rownames(train_set)<-c(1:nrow(train))
# rownames(test_set)<-c(1:nrow(test))
grid_search_vars <- list(minNodeWeightRF = seq(1,5,1),
rfNoTrees = seq(10,510,50),estimators= c( "InfGain",
"Gini",  "Accuracy")) %>%  purrr::cross_df()
fit_mod<-function(x,y,z){
fit.rand.forest = CoreModel(health_change~., data=train_set, model="rf", selectionEstimator=z, minNodeWeightRF=x, rfNoTrees=y)
return(fit.rand.forest)
}
grid_search_vars <- list(minNodeWeightRF = seq(1,5,2),
rfNoTrees = seq(10,310,50),estimators= c( "InfGain",
"Gini",  "Accuracy")) %>%  purrr::cross_df()
tm<-proc.time()
res<-pmap(list(grid_search_vars$minNodeWeightRF,grid_search_vars$rfNoTrees,grid_search_vars$estimators),fit_mod)
proc.time()-tm
#library(rpart)
library(caret)
#library(rpart.plot)
library(CORElearn)
#library(MASS)
#library(mlbench)
#library(alr3)
library(dplyr)
library(purrr)
set.seed(123)
load("C:/Users/Kostas/Desktop/Antonis - PHQ RF models/period_imp_diff.Rda")
df1<-df_delt
df1<-select(df1,health_change,walk_speed,gait,stand,tablet,WWUWorn,speech,speechSpeed,speechArousal,TV)
ss<- createDataPartition(df1$health_change, p = .7,
list = FALSE,
times = 1)
train_set<-df1[ss,]
test_set<-df1[-ss,]
#Useless?
#train<-train[complete.cases(train),]
# rownames(train_set)<-c(1:nrow(train))
# rownames(test_set)<-c(1:nrow(test))
grid_search_vars <- list(minNodeWeightRF = seq(1,5,2),
rfNoTrees = seq(10,310,50),estimators= c( "InfGain",
"Gini",  "Accuracy")) %>%  purrr::cross_df()
fit_mod<-function(x,y,z){
fit.rand.forest = CoreModel(health_change~., data=train_set, model="rf", selectionEstimator=z, minNodeWeightRF=x, rfNoTrees=y)
return(fit.rand.forest)
}
tm<-proc.time()
res<-pmap(list(grid_search_vars$minNodeWeightRF,grid_search_vars$rfNoTrees,grid_search_vars$estimators),fit_mod)
structure(list(Realizados = structure(1:25, .Label = c("Alterar Orçamento",
"Alterar Orçamento Cliente", "Alterar Sinistro", "Alterar Solicitação Manutenção",
"Alterar Solicitação Veículo", "CheckList", "Cliente", "Contrato Locação",
"COR", "Fornecedor", "Grupo Cliente", "Incluir Orçamento", "Incluir Sinistro",
"Incluir Solicitação Manutenção", "Incluir Solicitação Veículo",
"Modelo", "Multa", "Municipio", "Opcional", "Orçamento", "Serviço Peça",
"Sinistro", "Solicitação Manutenção", "Solicitação Veículo",
"Veículos"), class = "factor"), Atenção = structure(c(2L, 3L,
4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("", "Categoria", "Faturamento",
"Nota Fiscal"), class = "factor"), Regra = structure(c(2L, 3L,
6L, 4L, 5L, 7L, 8L, 9L, 10L, 11L, 12L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("", "Alterar Devolução Veículo",
"Classificação", "Devolução Veículo", "Editar Veículo Pool",
"Filial", "Incluir Devolução Veículo", "Infração", "Preventiva Realizada",
"Preventiva Realizar", "Tipo NF", "Veículo Pool"), class = "factor")), .Names = c("Realizados",
"Atenção", "Regra"), class = "data.frame", row.names = c(NA,
-25L))
aa<-structure(list(Realizados = structure(1:25, .Label = c("Alterar Orçamento",
"Alterar Orçamento Cliente", "Alterar Sinistro", "Alterar Solicitação Manutenção",
"Alterar Solicitação Veículo", "CheckList", "Cliente", "Contrato Locação",
"COR", "Fornecedor", "Grupo Cliente", "Incluir Orçamento", "Incluir Sinistro",
"Incluir Solicitação Manutenção", "Incluir Solicitação Veículo",
"Modelo", "Multa", "Municipio", "Opcional", "Orçamento", "Serviço Peça",
"Sinistro", "Solicitação Manutenção", "Solicitação Veículo",
"Veículos"), class = "factor"), Atenção = structure(c(2L, 3L,
4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("", "Categoria", "Faturamento",
"Nota Fiscal"), class = "factor"), Regra = structure(c(2L, 3L,
6L, 4L, 5L, 7L, 8L, 9L, 10L, 11L, 12L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("", "Alterar Devolução Veículo",
"Classificação", "Devolução Veículo", "Editar Veículo Pool",
"Filial", "Incluir Devolução Veículo", "Infração", "Preventiva Realizada",
"Preventiva Realizar", "Tipo NF", "Veículo Pool"), class = "factor")), .Names = c("Realizados",
"Atenção", "Regra"), class = "data.frame", row.names = c(NA,
-25L))
View(aa)
colSums(df)
n(aa$Realizados)
tally(df)
?tally
count(df)
rowSums( !is.na( aa))
colSums( !is.na( aa))
colSums(aa[aa!=""])
colSums(aa[aa!="",])
df
load("C:/Users/Kostas/Desktop/Antonis - PHQ RF models/2cats_gd.Rda")
df
df[1,]
load("C:/Users/Kostas/Desktop/Antonis - PHQ RF models/all_cats_gd.Rda")
df[1,]
setwd("C:/Users/Kostas/Desktop/Rblog")
build_site
()
library("blogdown", lib.loc="~/R/win-library/3.4")
build_site()
blogdown:::new_post_addin()
blogdown:::new_post_addin()
blogdown:::update_meta_addin()
blogdown:::serve_site()
